
# универсальный пайплайн для оценки GPT на всех GLUE-задачах через инструкции

## 1️⃣ Подготовка датасетов

* Берём все задачи GLUE через HuggingFace Datasets:
CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, RTE, WNLI, AX

* Для каждой задачи формируем prompt в стиле инструкции, как в нашей таблице.


## 2️⃣ Генерация промптов

Превращаем каждый пример в текстовую инструкцию:

| Задача | Пример prompt                                                                                                |   |                            |
| ------ | ------------------------------------------------------------------------------------------------------------ | - | -------------------------- |
| CoLA   | «Определи, грамматически ли корректно предложение: X. Ответь "Да" или "Нет".»                                |   |                            |
| SST-2  | «Определи тональность отзыва: X. Ответь "Положительный" или "Отрицательный".»                                |   |                            |
| MRPC   | «Являются ли эти предложения перефразами? X                                                                  |   | Y. Ответь "Да" или "Нет".» |
| STS-B  | «Оцени семантическое сходство этих предложений по шкале 0–5: X                                               |   | Y.»                        |
| QQP    | «Эти два вопроса — дубликаты? X                                                                              |   | Y. Ответь "Да" или "Нет".» |
| MNLI   | «Premise: X. Hypothesis: Y. Какое отношение между ними? Ответь "Entailment", "Contradiction" или "Neutral".» |   |                            |
| QNLI   | «Вопрос: Q. Текст: T. Является ли текст ответом на вопрос? Ответь "Да" или "Нет".»                           |   |                            |
| RTE    | «Premise: X. Hypothesis: Y. Следует ли гипотеза из текста? Ответь "Да" или "Нет".»                           |   |                            |
| WNLI   | «Предложение: X. Вопрос: на кого ссылается местоимение? 1) A 2) B. Ответь "1" или "2".»                      |   |                            |
| AX     | Формулируется аналогично RTE/MNLI, с уточнением категории ошибок                                             |   |                            |


## 3️⃣ Прогон через GPT

* Отправляем каждый prompt в GPT (zero-shot / few-shot).
* Сохраняем raw output.


## 4️⃣ Нормализация ответов

Приводим к единому формату:

* Да/Нет → entailment/not_entailment
* Entailment/Contradiction/Neutral → как есть
* Числовые ответы (STS-B) → float

Это нужно, чтобы корректно сравнивать с gold labels.


## 5️⃣ Подсчёт метрик

Для каждой задачи используем соответствующую метрику:

| Задача | Метрика                                  |
| ------ | ---------------------------------------- |
| CoLA   | MCC                                      |
| SST-2  | Accuracy                                 |
| MRPC   | Accuracy, F1                             |
| STS-B  | Pearson, Spearman                        |
| QQP    | Accuracy, F1                             |
| MNLI   | Accuracy (matched / mismatched)          |
| QNLI   | Accuracy                                 |
| RTE    | Accuracy                                 |
| WNLI   | Accuracy                                 |
| AX     | В зависимости от подзадачи (Accuracy/F1) |

